{
  "name": "AndroidCapture For Processing",
  "tagline": "This library tries to transfer data between Processing and Android.",
  "body": "# AndroidCapture For Processing\r\n\r\n**This library tries to transfer data between [Processing](https://processing.org) and [Android](https://android.com).** \r\n\r\nI make a android app to capture the real-time video from `\"Android Camera\"` and the real-time data from `\"Android Sensor\"` through the socket to the server (processing server) with `WiFi`. The users use this lib to get phone camera frame and sensors data in processing, then can do some interesting things. \r\n \r\n**Chinese Users** : Please look [Chinese Introduce](https://onlylemi.github.io/projects/processing-android-capture)\r\n \r\n> ### NOTICE\r\n**The current version is \"2.0.1\". Because of some library rules from processing.org, I only update some class name and delete 'P'. And other thing is same.** \r\n> \r\n* PAndroidCamera --> AndroidCamera\r\n* PAndroidSensor --> AndroidSensor\r\n* PSensor --> Sensor\r\n* PSensorType --> SensorType\r\n\r\nWelcome to try it and if there is a problem, please contact me or [new a issues](https://github.com/onlylemi/processing-android-capture/issues/new). \r\n\r\n## Android App\r\n **Repository** :  [https://github.com/onlylemi/AndroidCapture](https://github.com/onlylemi/AndroidCapture).  develope in [IntelliJ IDEA](https://www.jetbrains.com/idea/).  \r\n **My test phone** : [meilan note2](http://www.meizu.com/products/meilannote2/spec.html) and `android5.1`\r\n\r\n## DOWNLOAD\r\n**Latest release**: [v2.0.1](https://github.com/onlylemi/processing-android-capture/releases)\r\n\r\n\r\n\r\n## Installation\r\n* **Lib** Download the [latest library release](https://github.com/onlylemi/processing-android-capture/releases) and follow the steps described in the [Processing wiki](https://github.com/processing/processing/wiki/How-to-Install-a-Contributed-Library).\r\n* **Android Configuration** \r\n  * [download](https://raw.githubusercontent.com/onlylemi/processing-android-capture/master/android-apk/PAndroidCapture.apk) and install APK to your mobile phone\r\n  * open this software and slide out from the left side of the screen. You will see the configuration view. And click `Setting IP`, then input `the local address of your computer`. You must ensure that your mobile phone and your computer in the same Wifi.\r\n\r\n> ### local address of your computer\r\n* Windows --> look [here](http://www.howtogeek.com/117371/how-to-find-your-computers-private-public-ip-addresses/)\r\n* Mac --> look [here](http://www.wikihow.com/Find-Your-IP-Address-on-a-Mac)\r\n* Linux --> look [here](http://www.wikihow.com/Check-the-IP-Address-in-Linux)\r\n  \r\n## Folder\r\n* **android-apk**  \r\n  android phone client app in it.  \r\n  wandoujia:[http://www.wandoujia.com/apps/com.onlylemi.android.capture](http://www.wandoujia.com/apps/com.onlylemi.android.capture)\r\n*  **examples**\r\n  There are some primitive examples in it. The users download them and load `.jar` file in the project. The `.jar` file is set the named `'code'` folder.\r\n*  **library**\r\n  The `AndroidProcessingForProcessing.jar` file in it.\r\n*  **src** \r\n  The source code of this lib in it.\r\n\r\n## Examples\r\n### Android Camera: \r\n* The users use the `getCameraImage()` function to get android client phone camera frame and it will return a `PImage` object in processing. \r\n*  The users use the `getColor()` function to get color from android phone camera and it return a `int` object. \r\n\r\n\r\n**1. A primitive example to get phone camera image :**\r\n\r\n![android camera](https://raw.githubusercontent.com/onlylemi/processing-android-capture/master/camera_image.gif)\r\n```processing\r\nimport com.onlylemi.processing.android.capture.*;\r\n\r\nAndroidCamera ac;\r\nPImage img;\r\n\r\nvoid setup() {\r\n  size(720, 480);\r\n  ac = new AndroidCamera(width, height, 30);\r\n  ac.start();\r\n}\r\n\r\nvoid draw() {\r\n  // get android camera frame\r\n  img = ac.getCameraImage();\r\n  image(img, 0, 0);\r\n}\r\n```\r\n\r\n--\r\n\r\n**2. A primitive example to get the middle color of phone camera :**\r\n\r\n![android camera color](https://raw.githubusercontent.com/onlylemi/processing-android-capture/master/camera_color.gif)\r\n```processing\r\nimport com.onlylemi.processing.android.capture.*;\r\n\r\nAndroidCamera ac;\r\n\r\nvoid setup() {\r\n  size(720, 480);\r\n\r\n  ac = new AndroidCamera(width, height, 20);\r\n  ac.start();\r\n}\r\n\r\nvoid draw() {\r\n  background(0);\r\n  translate(width / 2, height / 2);\r\n\r\n  // get color from android camera\r\n  int c = ac.getColor();\r\n  fill(c);\r\n  ellipse(0, 0, 300, 300);\r\n}\r\n```\r\n\r\n### Android Sensor: \r\nThere is a class named `AndroidSensor` in this lib. And there are **8** sensors from android phone. The users get sensor type in class named `SensorType`. \r\n\r\n * SensorType.TYPE_ACCELEROMETER \r\n * SensorType.TYPE_LIGHT \r\n * SensorType.TYPE_ORIENTATION \r\n * SensorType.TYPE_PROXIMITY \r\n * SensorType.TYPE_TEMPERATURE \r\n * SensorType.TYPE_PRESSURE \r\n * SensorType.TYPE_GYROSCOPE \r\n * SensorType.TYPE_MAGNETIC_FIELD \r\n\r\n\r\n**1.  a example to get android sensor values:**\r\n\r\n![android sensor data](https://raw.githubusercontent.com/onlylemi/processing-android-capture/master/sensor_data.gif)\r\n```processing\r\nimport com.onlylemi.processing.android.capture.*;\r\n\r\nAndroidSensor as;\r\n\r\nvoid setup() {\r\n  size(720, 480);\r\n  background(0);\r\n\r\n  as = new AndroidSensor(0);\r\n  as.start();\r\n}\r\n\r\nvoid draw() {\r\n  background(0);\r\n  fill(255);\r\n  textSize(15);\r\n\r\n  text(SensorType.TYPE_ACCELEROMETER + \" : \", 60, 50);\r\n  float[] values1 = as.getAccelerometerSensorValues();\r\n  //float[] values1 = as.getSensorValues(SensorType.TYPE_ACCELEROMETER);\r\n  text(\"X : \" + values1[0], 250, 50);\r\n  text(\"Y : \" + values1[1], 400, 50);\r\n  text(\"Z : \" + values1[2], 550, 50);\r\n\r\n  text(SensorType.TYPE_ORIENTATION + \" : \", 60, 100);\r\n  float[] values2 = as.getOrientationSensorValues();\r\n  //float[] values2 = as.getSensorValues(SensorType.TYPE_ORIENTATION);\r\n  text(\"X : \" + values2[0], 250, 100);\r\n  text(\"Y : \" + values2[1], 400, 100);\r\n  text(\"Z : \" + values2[2], 550, 100);\r\n\r\n  text(SensorType.TYPE_MAGNETIC_FIELD + \" : \", 60, 150);\r\n  float[] values3 = as.getMagneticFieldSensorValues();\r\n  //float[] values3 = as.getSensorValues(SensorType.TYPE_MAGNETIC_FIELD);\r\n  text(\"X : \" + values3[0], 250, 150);\r\n  text(\"Y : \" + values3[1], 400, 150);\r\n  text(\"Z : \" + values3[2], 550, 150);\r\n\r\n  text(SensorType.TYPE_GYROSCOPE + \" : \", 60, 200);\r\n  float[] values4 = as.getGyroscopeSensorValues();\r\n  //float[] values4 = as.getSensorValues(SensorType.TYPE_GYROSCOPE);\r\n  text(\"X : \" + values4[0], 250, 200);\r\n  text(\"Y : \" + values4[1], 400, 200);\r\n  text(\"Z : \" + values4[2], 550, 200);\r\n\r\n  text(SensorType.TYPE_LIGHT + \" : \", 60, 250);\r\n  float values5 = as.getLightSensorValues();\r\n  //float values5 = as.getSensorValues(SensorType.TYPE_LIGHT)[0];\r\n  text(\"level : \" + values5, 250, 250);\r\n\r\n  text(SensorType.TYPE_PROXIMITY + \" : \", 60, 300);\r\n  float values6 = as.getProximitySensorValues();\r\n  //float values6 = as.getSensorValues(SensorType.TYPE_PROXIMITY)[0];\r\n  text(\"distance : \" + values6, 250, 300);\r\n\r\n  text(SensorType.TYPE_PRESSURE + \" : \", 60, 350);\r\n  float values7 = as.getPressureSensorValues();\r\n  //float[] values7 = as.getSensorValues(SensorType.TYPE_PRESSURE);\r\n  text(\"pressure : \" + values7, 250, 350);\r\n\r\n  text(SensorType.TYPE_TEMPERATURE + \" : \", 60, 400);\r\n  float values8 = as.getTemperatureSensorValues();\r\n  //float values8 = as.getSensorValues(SensorType.TYPE_TEMPERATURE);\r\n  text(\"temperature : \" + values8, 250, 400);\r\n}\r\n```\r\n\r\n--\r\n\r\n**2.  a example to use android sensor values:**\r\n\r\n![android sensor color](https://raw.githubusercontent.com/onlylemi/processing-android-capture/master/sensor_color.gif)\r\n\r\n```processing\r\nimport com.onlylemi.processing.android.capture.*;\r\n\r\nAndroidSensor as;\r\n\r\nvoid setup() {\r\n  size(720, 480);\r\n\r\n  background(0);\r\n\r\n  as = new AndroidSensor(0);\r\n  as.start();\r\n}\r\n\r\nvoid draw() {\r\n  // get accelerometer sensor value\r\n  //float[] values = as.getSensorValues(SensorType.TYPE_ACCELEROMETER);\r\n  float[] values = as.getAccelerometerSensorValues();\r\n  float x = values[0];\r\n  float y = values[1];\r\n  float z = values[2];\r\n\r\n  println(values);\r\n\r\n  int r = (int) (11.0f * (11.0f + x));\r\n  int g = (int) (11.0f * (11.0f + y));\r\n  int b = (int) (11.0f * (11.0f + z));\r\n\r\n  // background\r\n  noStroke();\r\n  fill(r, g, b, 25);\r\n  rect(0, 0, width, height);\r\n\r\n  // 3 circles\r\n  float x1 = ((int) (width / 20 * (9.5f + (1.0f) * y)));\r\n  float y1 = ((int) (height / 12 * (x + 6.0f)));\r\n  fill(255, 0, 0);\r\n  ellipse(x1, y1, 100, 100);\r\n\r\n  float x2 = ((int) (width / 20 * (9.5f + (-1.0f) * x)));\r\n  float y2 = ((int) (height / 12 * (y + 6.0f)));\r\n  fill(0, 255, 0);\r\n  ellipse(x2, y2, 100, 100);\r\n\r\n  float x3 = ((int) (width / 20 * (9.5f + (1.0f) * x)));\r\n  float y3 = ((int) (height / 12 * (y + 6.0f)));\r\n  fill(0, 0, 255);\r\n  ellipse(x3, y3, 100, 100);\r\n}\r\n```\r\n\r\n## CONTACT\r\n**Eamil:** onlylemi.com(AT)gmail.com\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}